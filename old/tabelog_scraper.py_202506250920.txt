from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from bs4 import BeautifulSoup
import os, time, re

# 出力ディレクトリとファイルパス設定
output_dir = r"D:\tabelog"
os.makedirs(output_dir, exist_ok=True)
output_file = os.path.join(output_dir, "tabelog_candidates.txt")
exclude_file = os.path.join(output_dir, "exclude_names.txt")
visited_file = os.path.join(output_dir, "visited.txt")

# 除外リストの読み込み
exclude_names = set()
visited_names = set()
if os.path.exists(exclude_file):
    with open(exclude_file, encoding="utf-8") as f:
        exclude_names = set(line.strip() for line in f if line.strip())
if os.path.exists(visited_file):
    with open(visited_file, encoding="utf-8") as f:
        visited_names = set(line.strip() for line in f if line.strip())
excluded = exclude_names.union(visited_names)

# 出力ファイル初期化（毎回上書き）
with open(output_file, "w", encoding="utf-8") as f:
    pass

# Chromeオプション設定
options = Options()
# options.add_argument("--headless")  # 必要に応じてヘッドレス化
options.add_argument("--disable-blink-features=AutomationControlled")
options.add_experimental_option("excludeSwitches", ["enable-automation"])
options.add_experimental_option("useAutomationExtension", False)
options.add_argument("user-agent=Mozilla/5.0")

# ドライバ起動
driver = webdriver.Chrome(options=options)
driver.execute_cdp_cmd("Page.addScriptToEvaluateOnNewDocument", {
    "source": "Object.defineProperty(navigator, 'webdriver', { get: () => undefined })"
})

# ページを5〜10までループ
for page in range(5, 11):
    print(f"\n📄 {page}ページ目 開始")
    driver.get(f"https://tabelog.com/kanagawa/rstLst/ramen/{page}/?Srt=D&SrtT=rt&sk=ラーメン")

    try:
        WebDriverWait(driver, 15).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, "div.list-rst__wrap"))
        )
    except Exception as e:
        print(f"❌ 読み込みNG: {e}")
        with open(os.path.join(output_dir, f"debug_page_{page}.html"), "w", encoding="utf-8") as debug_f:
            debug_f.write(driver.page_source)
        continue

    soup = BeautifulSoup(driver.page_source, "html.parser")
    cards = soup.select("div.list-rst__wrap")
    print(f"👉 見つかった: {len(cards)} 店舗")

    if len(cards) == 0:
        with open(os.path.join(output_dir, f"debug_page_{page}.html"), "w", encoding="utf-8") as debug_f:
            debug_f.write(driver.page_source)

    with open(output_file, "a", encoding="utf-8") as f:
        for card in cards:
            name_tag = card.select_one("a.list-rst__rst-name-target")
            score_tag = card.select_one("span.c-rating__val")
            rank_tag = card.select_one("span.c-ranking-badge__no")
            genre_tag = card.select_one("div.list-rst__area-genre")
            holiday_tag = card.select_one("span.list-rst__holiday-text")

            if not name_tag:
                continue

            name = name_tag.get_text(strip=True)
            url = name_tag["href"]
            if name in excluded:
                continue

            score = score_tag.get_text(strip=True) if score_tag else "?"
            rank = rank_tag.get_text(strip=True) if rank_tag else "?"
            station = ""
            if genre_tag:
                m = re.search(r"([^\s]+駅)", genre_tag.get_text())
                station = m.group(1) if m else ""

            closed = ""
            if holiday_tag:
                closed = "休：" + holiday_tag.get_text(strip=True)

            line1 = f"{rank}　{name}（{score}）{station}"
            if closed:
                line1 += f"　{closed}"

            print("→", line1)
            f.write(line1 + "\n")
            f.write(url + "\n\n")

    time.sleep(2)

driver.quit()
print("\n✅ 完了！出力ファイル確認してね。")
