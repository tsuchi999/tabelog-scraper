from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from bs4 import BeautifulSoup
import os, time, re

# 出力ディレクトリとファイルパス設定
output_dir = r"D:\tabelog"
os.makedirs(output_dir, exist_ok=True)
output_txt_file = os.path.join(output_dir, "tabelog_candidates.txt")
output_html_file = os.path.join(output_dir, "tabelog_candidates.html")
exclude_file = os.path.join(output_dir, "exclude_names.txt")
visited_file = os.path.join(output_dir, "visited.txt")

# 除外リストの読み込み
exclude_names = set()
visited_names = set()
if os.path.exists(exclude_file):
    with open(exclude_file, encoding="utf-8") as f:
        exclude_names = set(line.strip() for line in f if line.strip())
if os.path.exists(visited_file):
    with open(visited_file, encoding="utf-8") as f:
        visited_names = set(line.strip() for line in f if line.strip())
excluded = exclude_names.union(visited_names)

# 出力ファイル初期化（毎回上書き）
with open(output_txt_file, "w", encoding="utf-8") as f:
    pass

with open(output_html_file, "w", encoding="utf-8") as f:
    f.write("""<!DOCTYPE html>
<html lang="ja">
<head>
<meta charset="UTF-8">
<title>2025百名店候補店リスト</title>
<style>
  body { font-family: sans-serif; }
  table { border-collapse: collapse; width: 100%; }
  th, td { border: 1px solid #ccc; padding: 8px; text-align: left; }
  tr:nth-child(even) { background-color: #f9f9f9; }
  tr:nth-child(odd) { background-color: #ffffff; }
  th { background-color: #e0e0e0; }
</style>
</head>
<body>
<h2>2025百名店候補店リスト</h2>
<table>
  <tr><th>順位</th><th>店名（リンク）</th><th>スコア</th><th>最寄り駅</th><th>休業日</th></tr>
""")

# Chromeオプション設定
options = Options()
# options.add_argument("--headless")  # ヘッドレス化する場合は解除
options.add_argument("--disable-blink-features=AutomationControlled")
options.add_experimental_option("excludeSwitches", ["enable-automation"])
options.add_experimental_option("useAutomationExtension", False)
options.add_argument("user-agent=Mozilla/5.0")

# ドライバ起動
driver = webdriver.Chrome(options=options)
driver.execute_cdp_cmd("Page.addScriptToEvaluateOnNewDocument", {
    "source": "Object.defineProperty(navigator, 'webdriver', { get: () => undefined })"
})

# ページを5〜9までループ
for page in range(5, 10):
    print(f"\n📄 {page}ページ目 開始")
    driver.get(f"https://tabelog.com/kanagawa/rstLst/ramen/{page}/?Srt=D&SrtT=rt&sk=ラーメン")

    try:
        WebDriverWait(driver, 15).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, "div.list-rst__wrap"))
        )
    except Exception as e:
        print(f"❌ 読み込みNG: {e}")
        with open(os.path.join(output_dir, f"debug_page_{page}.html"), "w", encoding="utf-8") as debug_f:
            debug_f.write(driver.page_source)
        continue

    soup = BeautifulSoup(driver.page_source, "html.parser")
    cards = soup.select("div.list-rst__wrap")
    print(f"👉 見つかった: {len(cards)} 店舗")

    if len(cards) == 0:
        with open(os.path.join(output_dir, f"debug_page_{page}.html"), "w", encoding="utf-8") as debug_f:
            debug_f.write(driver.page_source)

    with open(output_txt_file, "a", encoding="utf-8") as txt_f, open(output_html_file, "a", encoding="utf-8") as html_f:
        for card in cards:
            name_tag = card.select_one("a.list-rst__rst-name-target")
            score_tag = card.select_one("span.c-rating__val")
            rank_tag = card.select_one("span.c-ranking-badge__no")
            genre_tag = card.select_one("div.list-rst__area-genre")
            holiday_tag = card.select_one("span.list-rst__holiday-text")

            if not name_tag:
                continue

            name = name_tag.get_text(strip=True)
            url = name_tag["href"]
            if name in excluded:
                continue

            score_raw = score_tag.get_text(strip=True) if score_tag else "?"
            score = float(score_raw) if score_raw.replace(".", "", 1).isdigit() else 0
            score_str = f'<span style="color:red">{score_raw}</span>' if score >= 3.62 else score_raw

            rank = rank_tag.get_text(strip=True) if rank_tag else "?"
            closed = holiday_tag.get_text(strip=True) if holiday_tag else ""

            # 最寄り駅 or 市区町村を抽出
            station = "-"
            if genre_tag:
                area_text = genre_tag.get_text(strip=True)
                if "/" in area_text:
                    station = area_text.split("/")[0].strip()
                else:
                    station = area_text.strip()

            # テキスト出力
            line1 = f"{rank}　{name}（{score_raw}）{station}"
            if closed:
                line1 += f"　休：{closed}"
            print("→", line1)
            txt_f.write(line1 + "\n")
            txt_f.write(url + "\n\n")

            # HTML出力（リンク付き店名＋スコアに色）
            html_f.write(f"""  <tr>
    <td>{rank}</td>
    <td><a href="{url}" target="_blank">{name}</a></td>
    <td>{score_str}</td>
    <td>{station}</td>
    <td>{closed}</td>
  </tr>
""")

    time.sleep(2)

# HTMLファイルの締めタグ
with open(output_html_file, "a", encoding="utf-8") as f:
    f.write("""
</table>
</body>
</html>
""")

driver.quit()
print("\n✅ 完了！txtもhtmlも出力OK、リンクも色分けも完璧やで✨")
