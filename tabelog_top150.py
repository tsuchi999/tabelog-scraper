import requests
from bs4 import BeautifulSoup
import os
import time
import datetime

# ========== åŸºæœ¬è¨­å®š ==========
base_url = "https://award.tabelog.com/hyakumeiten/ramen_kanagawa?page={}"
headers = {"User-Agent": "Mozilla/5.0"}

# ========== ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®š ==========
base_dir = r"D:\tabelog"
os.makedirs(base_dir, exist_ok=True)

exclude_file = os.path.join(base_dir, "exclude_names.txt")
visited_file = os.path.join(base_dir, "visited.txt")
hyakumeiten_file = os.path.join(base_dir, "hyakumeiten2025.txt")

# ========== é™¤å¤–åº—ãƒ»è¨ªå•åº—ãƒ»ç™¾ååº—ã®èª­ã¿è¾¼ã¿ ==========
exclude_names = set()
visited_names = set()
hyakumeiten_2025 = set()

def load_set_from_file(path):
    if os.path.exists(path):
        with open(path, "r", encoding="utf-8") as f:
            return {line.strip() for line in f if line.strip()}
    return set()

exclude_names = load_set_from_file(exclude_file)
visited_names = load_set_from_file(visited_file)
hyakumeiten_2025 = load_set_from_file(hyakumeiten_file)

print("é™¤å¤–:", len(exclude_names), "è¨ªå•:", len(visited_names), "ç™¾ååº—2025:", len(hyakumeiten_2025))

# ========== ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚° ==========
shop_list = []

for page in range(1, 10):  # ç™¾ååº—ãƒšãƒ¼ã‚¸ã¯1ã€œ9ã§150ä»¶åˆ°é”
    url = base_url.format(page)
    print(f"ğŸ“„ ãƒšãƒ¼ã‚¸å–å¾—: {url}")

    res = requests.get(url, headers=headers)
    soup = BeautifulSoup(res.text, "html.parser")

    cards = soup.select("div.p-restaurant-list__item")
    if not cards:
        break

    for c in cards:
        name_tag = c.select_one("a.p-restaurant-name")
        score_tag = c.select_one("b.c-rating__val")
        area_tag = c.select_one("span.p-restaurant-area")
        holiday_tag = c.select_one("span.p-restaurant-holiday-text")

        if not name_tag:
            continue

        name = name_tag.text.strip()
        url_info = name_tag.get("href")

        if name in exclude_names:
            print("ğŸš« é™¤å¤–:", name)
            continue

        score = score_tag.text.strip() if score_tag else "-"
        area = area_tag.text.strip() if area_tag else "-"
        holiday = holiday_tag.text.strip() if holiday_tag else "-"

        map_url = f"https://www.google.com/maps/search/?api=1&query={name}"

        shop_list.append((name, area, holiday, score, url_info, map_url))

        if len(shop_list) >= 150:
            break

    time.sleep(1)
    if len(shop_list) >= 150:
        break

# ========== HTML å‡ºåŠ› ==========
output_dir = r"D:\PythonScripts"
os.makedirs(output_dir, exist_ok=True)

html_path = os.path.join(output_dir, "hyakumeiten_best150.html")

today = datetime.datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")

with open(html_path, "w", encoding="utf-8") as f:
    f.write(f"""
<html>
<head>
<meta charset="utf-8">
<title>{today} ç¥å¥ˆå·ãƒ©ãƒ¼ãƒ¡ãƒ³ ä¸Šä½150åº—</title>
<style>
body {{ font-family: sans-serif; }}
table {{ border-collapse: collapse; width: 100%; }}
th, td {{ border: 1px solid #ccc; padding: 6px; }}
tr:nth-child(even) {{ background: #f9f9f9; }}
.orange {{ color: orange; font-weight: bold; }}
.green {{ color: green; font-weight: bold; }}
.rank {{ width: 5%; text-align: center; }}
</style>
</head>
<body>
<h2>{today} ç¥å¥ˆå·ãƒ©ãƒ¼ãƒ¡ãƒ³ ä¸Šä½150åº—</h2>
<table>
<tr>
<th class="rank">é †ä½</th>
<th>åº—å</th>
<th>ã‚¨ãƒªã‚¢</th>
<th>å®šä¼‘</th>
<th>ã‚¹ã‚³ã‚¢</th>
<th>INFO</th>
<th>MAP</th>
</tr>
""")

    for idx, (name, area, holiday, score, info_url, map_url) in enumerate(shop_list, start=1):

        # è‰²ä»˜ã‘
        if name in hyakumeiten_2025:
            name_html = f"<span class='orange'>{name}</span>"
        elif name in visited_names:
            name_html = f"<span class='green'>{name}</span>"
        else:
            name_html = name

        f.write(f"""
<tr>
<td class="rank">{idx}</td>
<td>{name_html}</td>
<td>{area}</td>
<td>{holiday}</td>
<td>{score}</td>
<td><a href="{info_url}" target="_blank">INFO</a></td>
<td><a href="{map_url}" target="_blank">MAP</a></td>
</tr>
""")

    f.write("</table></body></html>")

print("ğŸ‰ å®Œäº†ï¼ â†’", html_path)
